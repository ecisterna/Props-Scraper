# # Props Scraper - Scraping Autom√°tico de Propiedades

Este proyecto permite hacer scraping de propiedades de ArgentProp y programar ejecuciones autom√°ticas diarias que guardan los resultados en archivos Excel.

## üìÅ Estructura del Proyecto

```
Props-Scraper/
‚îú‚îÄ‚îÄ application.py              # Aplicaci√≥n Flask original
‚îú‚îÄ‚îÄ application_scheduler.py    # Aplicaci√≥n Flask con scheduler integrado
‚îú‚îÄ‚îÄ daily_scraper.py           # Script independiente para scraping diario
‚îú‚îÄ‚îÄ config_scraper.py          # Configurador de par√°metros
‚îú‚îÄ‚îÄ setup_task.bat            # Script para configurar tarea de Windows
‚îú‚îÄ‚îÄ requirements.txt           # Dependencias del proyecto
‚îú‚îÄ‚îÄ templates/                 # Plantillas HTML
‚îú‚îÄ‚îÄ resultados/               # Carpeta donde se guardan los Excel
‚îú‚îÄ‚îÄ logs/                     # Carpeta de logs
‚îî‚îÄ‚îÄ README.md                 # Este archivo
```

## üöÄ Opciones de Implementaci√≥n

### Opci√≥n 1: Aplicaci√≥n con Scheduler Integrado

La aplicaci√≥n Flask corre continuamente y ejecuta el scraping autom√°ticamente.

**Caracter√≠sticas:**
- ‚úÖ Scheduler integrado con APScheduler
- ‚úÖ Se ejecuta diariamente a las 9:00 AM
- ‚úÖ API REST para control manual
- ‚úÖ Interfaz web disponible
- ‚úÖ Configuraci√≥n modificable en tiempo real

**Uso:**
```bash
python application_scheduler.py
```

**Endpoints disponibles:**
- `GET /` - Interfaz web
- `GET /scrape_and_save` - Scraping manual y guardar en Excel
- `GET /config` - Ver configuraci√≥n actual
- `POST /config` - Modificar configuraci√≥n
- `GET /status` - Estado del scheduler

### Opci√≥n 2: Script Independiente + Programador de Windows

Script que se ejecuta una vez y termina, ideal para el Programador de tareas de Windows.

**Caracter√≠sticas:**
- ‚úÖ Ejecuci√≥n independiente
- ‚úÖ Logs detallados
- ‚úÖ Reporte de estad√≠sticas
- ‚úÖ Archivo hist√≥rico acumulativo
- ‚úÖ Configuraci√≥n mediante archivo JSON

**Configuraci√≥n autom√°tica:**
```bash
# Ejecutar como Administrador
setup_task.bat
```

**Ejecuci√≥n manual:**
```bash
python daily_scraper.py
```

## ‚öôÔ∏è Configuraci√≥n

### Configurar Par√°metros de Scraping

```bash
python config_scraper.py
```

Este script te permite modificar:
- Tipo de propiedad (departamentos/casas)
- Tipo de operaci√≥n (venta/alquiler)
- Ubicaci√≥n (capital-federal, zona-norte, etc.)
- Rango de precios
- Moneda (d√≥lares/pesos)
- N√∫mero m√°ximo de p√°ginas
- Criterio de ordenamiento

### Configuraci√≥n por Defecto

```json
{
  "property_type": "departamentos",
  "operation_type": "venta",
  "location": "capital-federal",
  "price_range_from": 50000,
  "price_range_to": 200000,
  "currency": "dolares",
  "max_pages": 5,
  "sort_by": "masnuevos"
}
```

## üìä Archivos de Salida

### Estructura de Excel Generado

Cada archivo Excel contiene las siguientes columnas:
- **Nombre**: T√≠tulo de la propiedad
- **Precio**: Precio de la propiedad
- **Direcci√≥n**: Ubicaci√≥n de la propiedad
- **Link**: URL completa a la propiedad
- **Fecha_Scraping**: Timestamp del scraping
- **Pagina**: N√∫mero de p√°gina donde se encontr√≥
- **Tipo_Propiedad**: Tipo de propiedad (departamentos/casas)
- **Tipo_Operacion**: Tipo de operaci√≥n (venta/alquiler)
- **Ubicacion**: Ubicaci√≥n buscada

### Archivos Generados

1. **Archivo Diario**: `scraping_departamentos_venta_YYYYMMDD.xlsx`
   - Resultados del d√≠a espec√≠fico

2. **Archivo Hist√≥rico**: `scraping_historico.xlsx`
   - Acumula todos los resultados hist√≥ricos
   - Elimina duplicados autom√°ticamente

## üîß Instalaci√≥n

1. **Clonar el repositorio**
```bash
git clone <repository-url>
cd Props-Scraper
```

2. **Crear entorno virtual**
```bash
python -m venv .venv
.venv\Scripts\activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

## üïí Programaci√≥n Autom√°tica

### Windows - Programador de Tareas

1. **Ejecuci√≥n autom√°tica del script de configuraci√≥n:**
```bash
# Ejecutar como Administrador
setup_task.bat
```

2. **Configuraci√≥n manual:**
- Abrir "Programador de tareas" de Windows
- Crear tarea b√°sica
- Nombre: "Props Scraper Daily"
- Desencadenador: Diariamente a las 9:00 AM
- Acci√≥n: Iniciar programa
- Programa: `C:\ruta\al\proyecto\.venv\Scripts\python.exe`
- Argumentos: `C:\ruta\al\proyecto\daily_scraper.py`

### Comandos √ötiles para el Programador de Tareas

```bash
# Ver la tarea
schtasks /query /tn "PropsScraper_Daily"

# Ejecutar manualmente
schtasks /run /tn "PropsScraper_Daily"

# Eliminar la tarea
schtasks /delete /tn "PropsScraper_Daily" /f
```

## üìã Logs y Monitoreo

### Logs del Script Independiente
- Ubicaci√≥n: `logs/scraping_YYYYMMDD.log`
- Contiene: Inicio/fin, errores, estad√≠sticas, resumen

### Logs del Scheduler Integrado
- Se muestran en la consola
- Incluyen informaci√≥n del scheduler y scraping

## üîç Resoluci√≥n de Problemas

### Problemas Comunes

1. **Error de permisos en Programador de tareas**
   - Ejecutar `setup_task.bat` como Administrador

2. **Timeout en requests**
   - Verificar conexi√≥n a internet
   - El script reintenta autom√°ticamente

3. **No se generan archivos Excel**
   - Verificar que existan datos para scrapear
   - Revisar logs para errores espec√≠ficos

4. **Scheduler no funciona**
   - Usar `use_reloader=False` en Flask
   - Verificar que no haya errores en el c√≥digo

### Verificar Estado

```python
# Para application_scheduler.py
# Visitar: http://localhost:5000/status

# Para daily_scraper.py
# Revisar logs en: logs/scraping_YYYYMMDD.log
```

## üìà Personalizaci√≥n

### Modificar Horario de Ejecuci√≥n

**Scheduler integrado (application_scheduler.py):**
```python
scheduler.add_job(
    func=scheduled_scraping,
    trigger="cron",
    hour=9,        # Cambiar hora aqu√≠
    minute=0,      # Cambiar minuto aqu√≠
    id='daily_scraping'
)
```

**Programador de Windows:**
- Modificar la l√≠nea `/st 09:00` en `setup_task.bat`

### Agregar Nuevos Par√°metros

1. Modificar `SCRAPING_CONFIG` en `daily_scraper.py`
2. Actualizar `DEFAULT_CONFIG` en `application_scheduler.py`
3. Agregar opciones en `config_scraper.py`

## ‚ö†Ô∏è Disclaimer

Este proyecto es solo para fines educativos. Aseg√∫rate de cumplir con los t√©rminos de servicio del sitio web que est√©s scrapeando y respeta los l√≠mites de rate limiting para evitar sobrecargar los servidores.
 
